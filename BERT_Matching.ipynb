{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shinju-M/Description-Request-Matching/blob/main/BERT_Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW7YV7SFjdY-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHiJjbEyiyOD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric, Dataset\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#device = torch.device('cuda')\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph4GroylN_P2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "torch.manual_seed(1000)\n",
        "\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5haqWTH03NKK",
        "outputId": "feff27a1-b52a-413d-a864-4bf7fbf5976b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "stop_ru = set(stopwords.words('russian'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Shinju-M/Description-Request-Matching/main/datasets/data_train.csv\n",
        "!wget https://raw.githubusercontent.com/Shinju-M/Description-Request-Matching/main/datasets/data_test.csv"
      ],
      "metadata": {
        "id": "TtqNKb9e6LHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHkR_dovjKEM"
      },
      "outputs": [],
      "source": [
        "# train data\n",
        "train_df = pd.read_csv('data_train.csv', sep = ',', index_col=False)\n",
        "train_profiles = train_df['profile'].astype('str')\n",
        "train_requests = train_df['text'].astype('str')\n",
        "train_labels_bin = train_df['match_bin']\n",
        "train_labels_cat = train_df['match_cat'].apply(lambda x: x - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AsdA8wwC5wY"
      },
      "outputs": [],
      "source": [
        "# test data\n",
        "test_df = pd.read_csv('data_test.csv', sep = ',')\n",
        "test_profiles = test_df['profile'].astype('str')\n",
        "test_requests = test_df['text'].astype('str')\n",
        "test_labels_bin = test_df['match_bin']\n",
        "test_labels_cat = test_df['match_cat'].apply(lambda x: x - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TVneycBIov5"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BHLl46B4UC9"
      },
      "outputs": [],
      "source": [
        "# clean function\n",
        "\n",
        "# def clean_text(text):\n",
        "#   text = re.sub(r'[,.?“/!@#$:#—ツ►๑۩۞۩•*”˜˜”*°°*`)\"(]', '', text)\n",
        "#   text = [word.strip().lower() for word in text.split()]\n",
        "#   return ' '.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOpxCdRn4jmu"
      },
      "outputs": [],
      "source": [
        "# clean and lemmatize function\n",
        "# import pymystem3\n",
        "# m = pymystem3.Mystem()\n",
        "\n",
        "# def clean_text(text):\n",
        "#   text = re.sub(r'[,.?“/!@#$:#—ツ►๑۩۞۩•*”˜˜”*°°*`)\"(]', '', text)\n",
        "#   text = [word.strip().lower() for word in m.lemmatize(text)]\n",
        "#   return ' '.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f7PfzzxNICV"
      },
      "outputs": [],
      "source": [
        "# simplier clean for BERT\n",
        "\n",
        "def clean_text(text):\n",
        "  text = re.sub(r'\\n', ' ', text)\n",
        "  text = re.sub(r'\"', '', text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a7SeDG1osV6"
      },
      "outputs": [],
      "source": [
        "# train data cleaning\n",
        "train_profiles_clean = []\n",
        "for text in train_profiles:\n",
        "  text = clean_text(text)\n",
        "  train_profiles_clean.append(text)\n",
        "\n",
        "train_df['profile'] = train_profiles_clean\n",
        "\n",
        "train_requests_clean = []\n",
        "for text in train_requests:\n",
        "  text = clean_text(text)\n",
        "  train_requests_clean.append(text)\n",
        "\n",
        "train_df['text'] = train_requests_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsmL110UEM0J"
      },
      "outputs": [],
      "source": [
        "# test data cleaning\n",
        "test_profiles_clean = []\n",
        "for text in test_profiles:\n",
        "  text = clean_text(text)\n",
        "  test_profiles_clean.append(text)\n",
        "\n",
        "test_df['profile'] = test_profiles_clean\n",
        "\n",
        "test_requests_clean = []\n",
        "for text in test_requests:\n",
        "  text = clean_text(text)\n",
        "  test_requests_clean.append(text)\n",
        "\n",
        "test_df['text'] = test_requests_clean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df.to_csv('data_train.csv')\n",
        "# test_df.to_csv('data_test.csv')"
      ],
      "metadata": {
        "id": "0D6AXf4qyeec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "mdLhsEIgJj7H",
        "outputId": "2b8734bc-1f91-4c4f-d42f-dbad69bf6026"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# text length distribution graph\n",
        "\n",
        "# seq_len = [len(str(i).split()) for i in train_pairs]\n",
        "# pd.Series(seq_len).hist(bins = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyXgJ2CeJjDY"
      },
      "source": [
        "BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4qwq56cOsT2"
      },
      "outputs": [],
      "source": [
        "bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased-sentence')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxlhVbsXGvSZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsPGVz6fXt3"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGm6sbI_sPyV",
        "outputId": "0d766527-8110-49ea-d0a1-3baa16858682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "# train data prep\n",
        "train_tokens = tokenizer(\n",
        "    train_df['text'].tolist(),\n",
        "    train_df['profile'].tolist(),\n",
        "    max_length = MAX_LEN,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "train_seq = torch.tensor(train_tokens['input_ids'])\n",
        "train_mask = torch.tensor(train_tokens['attention_mask'])\n",
        "train_y = torch.tensor(train_labels_cat.values, dtype=torch.long)\n",
        "\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_seq)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZXcmq-itWRs",
        "outputId": "de81bdb4-dd5a-4ac4-b586-d8c11ce178b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "test_tokens = tokenizer(\n",
        "    test_df['text'].tolist(),\n",
        "    test_df['profile'].tolist(),\n",
        "    max_length = MAX_LEN,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "test_seq = torch.tensor(test_tokens['input_ids'])\n",
        "test_mask = torch.tensor(test_tokens['attention_mask'])\n",
        "test_y = torch.tensor(test_labels_cat.values, dtype=torch.long)\n",
        "\n",
        "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "test_sampler = RandomSampler(test_seq)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2GcgHxXuezE"
      },
      "outputs": [],
      "source": [
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piYVFM3tI6O-"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(768,512)\n",
        "        self.fc2 = nn.Linear(512,5)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
        "        x = self.fc1(cls_hs)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8kq9Wm8JXSC"
      },
      "outputs": [],
      "source": [
        "model = BERT_Arch(bert)\n",
        "\n",
        "# model = model.to(device)\n",
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)\n",
        "\n",
        "# weights = weights.to(device)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dHrZEk-stUZ"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds = []\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "      sent_id,mask,labels = batch\n",
        "      model.zero_grad()\n",
        "      preds = model(sent_id, mask)\n",
        "      loss = cross_entropy(preds, labels)\n",
        "      total_loss += loss.item()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  total_preds = np.concatenate(total_preds, axis = 0)\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEqawWxtJ3sK"
      },
      "outputs": [],
      "source": [
        "def evaluate():\n",
        "    model.eval()\n",
        "    total_loss, total_accuracy = 0,0\n",
        "    total_preds = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(sent_id, mask)\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss = total_loss + loss.item()\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    avg_loss = total_loss / len(test_dataloader)\n",
        "    total_preds = np.concatenate(total_preds, axis = 0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyA35GN0LQiH"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
        "\n",
        "    train_loss, _ = train()\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'/content/drive/MyDrive/weights_{epoch}_p.pt')\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
        "    print(f'Validation loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z4ZjXlesMvE",
        "outputId": "7351ab3e-71c0-4912-a330-9b8ef9a5f228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB4Y9PVbgVwr",
        "outputId": "10592eb3-9213-4cea-ac59-839aed0b5167"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/weights_7.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpYv9R4f089E"
      },
      "outputs": [],
      "source": [
        "def match(request, profile):\n",
        "    pair = list([[str(request), str(profile)]])\n",
        "\n",
        "    tokens = tokenizer.batch_encode_plus(\n",
        "    pair,\n",
        "    max_length = MAX_LEN,\n",
        "    padding = 'max_length',\n",
        "    truncation = True\n",
        ")\n",
        "\n",
        "    seq = torch.tensor(tokens['input_ids'])\n",
        "    mask = torch.tensor(tokens['attention_mask'])\n",
        "\n",
        "    output = model(seq, mask)\n",
        "    _, prediction = torch.max(output, dim=1)\n",
        "    return prediction+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAvwUkjRaLbz"
      },
      "outputs": [],
      "source": [
        "request = 'Здравствуйте. Нужен семейный психолог. Тривиально... семья распадается . Но этого бы никто не хотел'\n",
        "profile = test_df['profile'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p73p81oCgRcc"
      },
      "outputs": [],
      "source": [
        "train_pairs = train_df[['text', 'profile']].values.astype('str').tolist()\n",
        "test_pairs = test_df[['text', 'profile']].values.astype('str').tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import classification_report"
      ],
      "metadata": {
        "id": "ducgIvVsHNME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgqF0wQpesxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab32296-4835-442d-9927-4c220e01b68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "y_true = test_df['match_cat']\n",
        "y_preds = []\n",
        "for request, profile in test_pairs:\n",
        "  y_preds.append(int(match(request, profile)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sx4SsWRHXG3",
        "outputId": "e779f368-11c7-43a8-bda0-1fbf85102c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.36      1.00      0.53         5\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.07      0.20      0.11        16\n",
            "weighted avg       0.11      0.31      0.16        16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}